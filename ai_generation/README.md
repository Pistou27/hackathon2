Pipeline de GÃ©nÃ©ration de Contenu par IA (Hackathon 2)
PrÃ©sentation du projet

Ce projet expÃ©rimental propose deux volets complÃ©mentaires autour de la gÃ©nÃ©ration de contenu par IA, dÃ©veloppÃ©s lors dâ€™un hackathon :

    Volet 1 : GÃ©nÃ©ration de posts (type LinkedIn) â€“ Un pipeline modulaire pour gÃ©nÃ©rer automatiquement un texte court Ã  partir dâ€™un sujet donnÃ©, avec contrÃ´les de qualitÃ© : rÃ©sumÃ© automatique, vÃ©rification de cohÃ©rence, filtrage Ã©thique, et mÃªme une tentative de gÃ©nÃ©ration dâ€™image via un VAE. Lâ€™objectif Ã©tait dâ€™obtenir un systÃ¨me 100% exÃ©cutable sur CPU (pas de GPU ni dâ€™API externe) pour produire des posts de qualitÃ© tout en Ã©vitant les dÃ©rives (hallucinations, contenus offensants). Ce volet nâ€™a pas Ã©tÃ© entiÃ¨rement finalisÃ©, notamment par manque de modÃ¨les puissants optimisÃ©s CPU et de temps pour peaufiner les rÃ©sultats.

    Volet 2 : GÃ©nÃ©ration dâ€™articles de blog â€“ Une seconde approche, fonctionnelle, axÃ©e sur la gÃ©nÃ©ration dâ€™articles de blog (~300 mots) Ã  partir dâ€™un thÃ¨me. Ce pipeline produit un article structurÃ© (introduction, parties, conclusion), gÃ©nÃ¨re un rÃ©sumÃ© automatique de lâ€™article, et illustre le tout avec une image crÃ©Ã©e par un modÃ¨le de diffusion. Lâ€™ensemble du processus est automatisÃ© et peut Ãªtre planifiÃ© (gÃ©nÃ©ration pÃ©riodique dâ€™articles), avec des scripts dâ€™ordonnancement et une interface de visualisation des articles gÃ©nÃ©rÃ©s. Ce volet utilise des modÃ¨les plus rÃ©cents et performants (toujours exÃ©cutables sur CPU) pour amÃ©liorer la cohÃ©rence et la qualitÃ© du contenu.

Volet 1 : GÃ©nÃ©ration de posts (LinkedIn)

Objectif : Automatiser la crÃ©ation de posts courts de type LinkedIn Ã  partir dâ€™un prompt/sujet, tout en filtrant les contenus indÃ©sirables. Le pipeline complet enchaÃ®ne plusieurs Ã©tapes de NLP :

Prompt utilisateur 
â†“
distilGPT2 â€” gÃ©nÃ©ration du texte initial 
â†“
distilBART â€” rÃ©sumÃ© automatique du texte 
â†“
MiniLM â€” vÃ©rification de similaritÃ© rÃ©sumÃ©/sujet 
â†“
Filtre Ã©thique (regex & mots-clÃ©s) 
â†“
âœ… Texte final acceptÃ© (ou âŒ rejetÃ© si contenu inappropriÃ©)

DÃ©tails du pipeline : Lâ€™utilisateur fournit un sujet de post. Un modÃ¨le GPT-2 distillÃ© (distilgpt2) gÃ©nÃ¨re un texte initial relativement long. Ce texte est ensuite rÃ©sumÃ© via un modÃ¨le DistilBART-CNN (distilBART entraÃ®nÃ© sur CNN/DailyMail) pour obtenir une version condensÃ©e plus cohÃ©rente (rÃ©duction des Ã©ventuelles Â« hallucinations Â» du modÃ¨le GPT-2). On calcule ensuite la similaritÃ© sÃ©mantique entre le sujet initial et le rÃ©sumÃ© Ã  lâ€™aide dâ€™un encodeur Sentence-Transformers MiniLM (all-MiniLM-L6-v2) afin de sâ€™assurer que le contenu gÃ©nÃ©rÃ© reste pertinent par rapport au prompt. Un filtrage Ã©thique est appliquÃ© sur le texte (par exemple via des regex ou une liste de mots sensibles) pour dÃ©tecter des propos offensants, du contenu inappropriÃ© ou des dÃ©rives non souhaitÃ©es. Si le texte Ã©choue aux critÃ¨res (faible similaritÃ© ou contenu problÃ©matique), il peut Ãªtre marquÃ© ou rejetÃ© ; sinon, le post final est produit. Le pipeline prÃ©voit Ã©galement un marquage du texte final (par exemple en ajoutant des indications si le contenu a Ã©tÃ© filtrÃ© ou modifiÃ©).

Ã‰valuation : Des scripts dâ€™Ã©valuation (calcul du BLEU, ROUGE-L, etc.) permettent de mesurer la qualitÃ© des textes gÃ©nÃ©rÃ©s et la robustesse du pipeline. Un fichier de prompts adversariaux (adversarial_prompts.txt) est fourni pour tester la robustesse du systÃ¨me face Ã  des entrÃ©es absurdes ou malveillantes. Lors des tests initiaux, le pipeline obtenait environ BLEU = 0,25, ROUGE-L = 0,45, une similaritÃ© moyennne de ~0,72 entre le rÃ©sumÃ© et le prompt, et un taux de dÃ©tection Ã©thique de ~5% (proportion de textes contenant des mots sensibles dÃ©tectÃ©s).

Limites : Ce premier volet a dÃ©montrÃ© la faisabilitÃ© dâ€™une gÃ©nÃ©ration multi-Ã©tapes sur CPU, mais avec des compromis de performance. Les modÃ¨les allÃ©gÃ©s (distilGPT2, distilBART, MiniLM) tournent sans GPU mais restent limitÃ©s en qualitÃ© : le contenu gÃ©nÃ©rÃ© peut manquer de richesse ou de fiabilitÃ©, nÃ©cessitant le rÃ©sumÃ© pour corriger les incohÃ©rences. MalgrÃ© les contrÃ´les, GPT-2 peut produire du hors-sujet ou du texte peu naturel. Le filtrage Ã©thique par mots-clÃ©s/regex reste sommaire (une amÃ©lioration envisagÃ©e Ã©tait dâ€™entraÃ®ner un classifieur de toxicitÃ© local). Enfin, la gÃ©nÃ©ration dâ€™images par VAE (rÃ©seau auto-encodeur variationnel) est restÃ©e expÃ©rimentale : un petit VAE a Ã©tÃ© entraÃ®nÃ© (ex. sur MNIST) pour gÃ©nÃ©rer des images basiques, sans rapport sÃ©mantique avec le post (plutÃ´t une preuve de concept). Faute de modÃ¨les dâ€™image adaptÃ©s au CPU et de donnÃ©es suffisantes, cette partie nâ€™a pas abouti Ã  des illustrations exploitables pour un post LinkedIn professionnel.
Volet 2 : GÃ©nÃ©ration dâ€™articles de blog

Objectif : Produire de faÃ§on autonome des articles de blog complets, avec rÃ©sumÃ© et image, Ã  partir dâ€™un thÃ¨me donnÃ©. Ce second pipeline amÃ©liore la qualitÃ© du texte et intÃ¨gre une vÃ©ritable gÃ©nÃ©ration dâ€™images. Le processus global est le suivant :

Sujet dâ€™article (thÃ¨me) 
â†“
LaMini-Flan-T5 (783 M) â€” gÃ©nÃ©ration de lâ€™article complet 
â†“
DistilBART â€” rÃ©sumÃ© automatique de lâ€™article 
â†“
MiniLM â€” vÃ©rification de similaritÃ© article/rÃ©sumÃ© 
â†“
Filtre Ã©thique (profanitÃ©s via better-profanity) 
â†“
Stable Diffusion (Diffusers) â€” image dâ€™illustration 
â†“
Article final en Markdown (texte + rÃ©sumÃ© + image)

DÃ©tails du pipeline : On utilise un modÃ¨le de texte plus puissant, LaMini-Flan-T5 (783 millions de paramÃ¨tres), capable de suivre des consignes en franÃ§ais. Lâ€™article est gÃ©nÃ©rÃ© en une Ã©tape sous forme structurÃ©e : le prompt de gÃ©nÃ©ration inclut des instructions explicites (Â« Ã‰cris un article de blog structurÃ© de 250 Ã  300 motsâ€¦ avec Titre, introduction, parties, conclusionâ€¦ Â») afin dâ€™obtenir un texte bien organisÃ© et de longueur cible sans Ã©tape de rÃ©sumÃ© intermÃ©diaire. NÃ©anmoins, pour extraire un rÃ©sumÃ© court (par exemple pour un aperÃ§u ou SEO), le pipeline emploie un DistilBART (identique au volet 1) ou un modÃ¨le Ã©quivalent pour rÃ©sumer lâ€™article gÃ©nÃ©rÃ©. La cohÃ©rence entre lâ€™article et son rÃ©sumÃ© est vÃ©rifiÃ©e avec le mÃªme Sentence-Transformer MiniLM, pour dÃ©tecter dâ€™Ã©ventuelles digressions. Le filtre Ã©thique a Ã©tÃ© amÃ©liorÃ© en intÃ©grant la librairie better-profanity qui repÃ¨re les insultes/propos offensants de maniÃ¨re plus systÃ©matique (via un dictionnaire de grossiÃ¨retÃ©s).

Une fois le texte validÃ©, le pipeline gÃ©nÃ¨re une image dâ€™illustration du sujet grÃ¢ce Ã  Stable Diffusion (via HuggingFace Diffusers). Pour rester dans des temps de calcul raisonnables sur CPU, on utilise un nombre rÃ©duit dâ€™itÃ©rations (par ex. 15 steps de diffusion) et un prompt dâ€™image simplifiÃ© (par ex. Â« {sujet}, vector illustration, flat design, vibrant colors Â» avec un prompt nÃ©gatif pour Ã©viter le texte ou le flou). Lâ€™image obtenue (format PNG) illustre visuellement le thÃ¨me de lâ€™article.

Production et sortie : Lâ€™article final est sauvegardÃ© dans un fichier Markdown comprenant : un titre (le sujet), le texte de lâ€™article, puis une section â€œRÃ©sumÃ©â€ gÃ©nÃ©rÃ©e, une indication du score de similaritÃ© sÃ©mantique, et le statut du filtrage Ã©thique (âœ… aucun problÃ¨me ou âš ï¸ dÃ©tails des contenus sensibles dÃ©tectÃ©s). Si une illustration a Ã©tÃ© crÃ©Ã©e, elle est rÃ©fÃ©rencÃ©e dans le Markdown. Un fichier JSON de mÃ©tadonnÃ©es accompagne chaque article (contenant le titre/sujet, la date/heure de gÃ©nÃ©ration, le rÃ©sumÃ©, le score de similaritÃ©, le statut du filtre et les Ã©tiquettes de contenu sensible le cas Ã©chÃ©ant, ainsi que le nom de lâ€™image associÃ©e).

Les articles et leurs ressources sont rangÃ©s par date dans un dossier de sortie (voir arborescence). Une interface Streamlit (blog_viewer.py) permet dâ€™afficher la liste des articles gÃ©nÃ©rÃ©s avec leur date, le contenu formatÃ© et lâ€™illustration, simulant un blog automatisÃ© alimentÃ© par lâ€™IA.

Ordonnancement : Ce volet intÃ¨gre un script de planification (run_scheduler.py) utilisant la librairie schedule. Par exemple, il peut Ãªtre configurÃ© pour gÃ©nÃ©rer automatiquement un nouvel article toutes les heures ou tous les jours Ã  heure fixe. (Le sujet peut Ãªtre fixÃ© dans le script ou choisi alÃ©atoirement/parmi une liste de thÃ¨mes.) Cela permet dâ€™automatiser la crÃ©ation de contenu rÃ©gulier sur le blog IA.

Limites : MalgrÃ© lâ€™utilisation de modÃ¨les plus grands, tout tourne sur CPU, ce qui implique des temps de gÃ©nÃ©ration assez longs (plusieurs dizaines de secondes pour gÃ©nÃ©rer ~300 mots, et jusquâ€™Ã  1-2 minutes pour lâ€™image selon la machine). La qualitÃ© des articles est nettement meilleure quâ€™avec GPT-2, mais reste tributaire du modÃ¨le T5 utilisÃ© : il peut encore y avoir des imprÃ©cisions ou un style gÃ©nÃ©rique. Le rÃ©sumÃ© automatique peut parfois rÃ©pÃ©ter des infos Ã©videntes. La gÃ©nÃ©ration dâ€™images via Stable Diffusion sur CPU est trÃ¨s lente et consommatrice en mÃ©moire ; la rÃ©solution et les dÃ©tails ont Ã©tÃ© limitÃ©s (ex: style illustration vectorielle) pour accÃ©lÃ©rer le rendu. Enfin, le pipeline nâ€™est pas Ã  lâ€™abri de hallucinations ou de biais du modÃ¨le (mÃªme si on les a rÃ©duits) : une supervision humaine reste recommandÃ©e avant publication rÃ©elle des contenus.
Technologies et modÃ¨les utilisÃ©s

Les deux volets sâ€™appuient sur un Ã©cosystÃ¨me Python centrÃ© sur le NLP de HuggingFace et dâ€™autres librairies open-source :

    Transformers (HuggingFace) â€“ UtilisÃ© pour charger et exÃ©cuter les modÃ¨les de gÃ©nÃ©ration de texte et de rÃ©sumÃ©.

        ModÃ¨les texte : distilgpt2 (GPT-2 distillÃ©) pour la gÃ©nÃ©ration initiale (volet 1), puis MBZUAI/LaMini-Flan-T5-783M (un modÃ¨le Flan-T5 de 783M paramÃ¨tres) pour la gÃ©nÃ©ration dâ€™articles (volet 2).

        ModÃ¨le de rÃ©sumÃ© : sshleifer/distilbart-cnn-12-6 (DistilBART entraÃ®nÃ© sur CNN/Daily Mail) pour rÃ©sumer les textes longs.

        Autres : la librairie transformers est Ã©galement utilisÃ©e pour le fine-tuning LoRA GPT-2 (une tentative dâ€™adapter GPT-2-medium via Low-Rank Adaption, visible dans le dÃ©pÃ´t, bien que cela ne soit pas intÃ©grÃ© au pipeline final).

    Sentence-Transformers â€“ Fournit le modÃ¨le all-MiniLM-L6-v2 (MiniLM) qui gÃ©nÃ¨re des embeddings sÃ©mantiques pour mesurer la similaritÃ© cosinus entre le prompt, le rÃ©sumÃ© et/ou lâ€™article. Ceci permet un scoring de cohÃ©rence (vÃ©rification que le contenu gÃ©nÃ©rÃ© reste dans le sujet).

    Diffusers (HuggingFace) â€“ Pour la gÃ©nÃ©ration dâ€™images par diffusion (Stable Diffusion). Un pipeline de diffusion textuelle est employÃ© (modÃ¨le Stable Diffusion v1.5 par dÃ©faut) afin de crÃ©er une image correspondant au thÃ¨me de lâ€™article, en utilisant uniquement le CPU. Inclut lâ€™utilisation de accelerate et safetensors pour optimiser le chargement des modÃ¨les de diffusion en mÃ©moire.

    PyTorch â€“ Backend principal pour les modÃ¨les de deep learning (transformers et diffusers). UtilisÃ© Ã©galement pour le VAE personnalisÃ© (dÃ©finition du modÃ¨le dans vae_model.py et entraÃ®nement sur un petit dataset).

    NLTK, rouge-score â€“ EmployÃ©s pour lâ€™Ã©valuation linguistique (tokenization et calcul de mÃ©triques BLEU/ROUGE dans le volet 1, via nltk pour BLEU et rouge-score pour ROUGE-L). NLTK sert aussi dans le volet 2 pour des utilitaires NLP (par ex. dÃ©coupage en phrases si nÃ©cessaire).

    scikit-learn â€“ UtilisÃ© notamment pour des calculs de similaritÃ© (cosine similarity) ou dâ€™autres mÃ©triques dâ€™Ã©valuation. Dans ce contexte, il peut intervenir pour la partie vÃ©rification de cohÃ©rence ou le traitement des vecteurs issus de Sentence-Transformers.

    better-profanity â€“ Librairie lÃ©gÃ¨re de dÃ©tection de grossiÃ¨retÃ©s/profanitÃ©s dans du texte. IntÃ©grÃ©e dans ethical_filter_v2.py (volet 2) pour amÃ©liorer le filtrage Ã©thique en repÃ©rant automatiquement les mots offensants courants (en franÃ§ais et anglais).

    schedule â€“ Librairie de planification dâ€™Ã©vÃ©nements cron-like. UtilisÃ©e dans les scripts scheduler.py (volet 1) et run_scheduler.py (volet 2) pour automatiser lâ€™exÃ©cution pÃ©riodique du pipeline (par ex. toutes les heures). Cela permet de dÃ©ployer le systÃ¨me en tÃ¢che de fond gÃ©nÃ©rant rÃ©guliÃ¨rement du contenu.

    Streamlit â€“ Framework web pour crÃ©er rapidement des interfaces utilisateur. Deux applications Streamlit sont fournies : app.py (volet 1) propose une interface de dÃ©mo pour gÃ©nÃ©rer des posts filtrÃ©s en direct, et blog_viewer.py (volet 2) offre une interface type dashboard pour visualiser les articles de blog gÃ©nÃ©rÃ©s (avec leur rÃ©sumÃ©, stats et image). Ces UIs ont Ã©tÃ© utilisÃ©es pour la prÃ©sentation du projet (elles ne sont pas obligatoires pour faire fonctionner les pipelines, mais facilitent lâ€™interaction et la dÃ©monstration).

    Autres : datasets (HuggingFace Datasets) pour Ã©ventuellement charger un jeu de donnÃ©es (un exemple mentionnÃ© est IMDB, possiblement utilisÃ© lors de tests ou dâ€™un fine-tuning), peft (Parameter-Efficient Fine-Tuning) pour le LoRA GPT-2 fine-tuning, torchvision et matplotlib pour le VAE (traitement dâ€™images, affichage de rÃ©sultats dâ€™entraÃ®nement), PyPDF2, pdfplumber et python-docx pour la lecture de documents (PDF/DOCX) â€“ ces derniers Ã©taient prÃ©vus pour enrichir le systÃ¨me (par ex. extraire du texte de documents dâ€™entrÃ©e), mais sont optionnels et non au cÅ“ur de la gÃ©nÃ©ration de contenu.

Arborescence du projet

Le rÃ©pertoire ai_generation/ contient lâ€™ensemble des fichiers source, organisÃ©s en parties correspondantes aux deux volets :

ai_generation/  
â”œâ”€â”€ README.md                  - PrÃ©sentation initiale du projet (pipeline du volet LinkedIn)  
â”œâ”€â”€ adversarial_prompts.txt    - Prompts Â« adversaires Â» pour tester la robustesse (volet 1)  
â”œâ”€â”€ app.py                     - Application web Streamlit de dÃ©monstration (volet 1)  
â”œâ”€â”€ automate.py                - Script CLI pour exÃ©cuter le pipeline complet une fois (volet 1)  
â”œâ”€â”€ scheduler.py               - Script dâ€™ordonnancement (schedule) pour exÃ©cutions rÃ©guliÃ¨res (volet 1)  
â”œâ”€â”€ data_loader.py             - Chargement de dataset (ex: IMDB) pour tests ou entraÃ®nement  
â”œâ”€â”€ ethical_filter.py          - Filtrage Ã©thique basique par mots-clÃ©s/expressions rÃ©guliÃ¨res  
â”œâ”€â”€ evaluation.py              - Ã‰valuation du texte gÃ©nÃ©rÃ© (mÃ©triques BLEU, ROUGE, etc., volet 1)  
â”œâ”€â”€ generation.py              - GÃ©nÃ©rateur de texte (volet 1, classe *TextGenerator* avec distilGPT2)  
â”œâ”€â”€ summarization.py           - RÃ©sumeur de texte (volet 1, utilise DistilBART CNN)  
â”œâ”€â”€ similarity.py              - VÃ©rification de similaritÃ© sÃ©mantique (encodeur MiniLM)  
â”œâ”€â”€ utils.py                   - Fonctions utilitaires diverses (volet 1)  
â”œâ”€â”€ vae_images/                - **(ExpÃ©rimental)** GÃ©nÃ©ration dâ€™images par VAE  
â”‚   â”œâ”€â”€ vae_model.py           - DÃ©finition du modÃ¨le VAE (auto-encodeur variationnel)  
â”‚   â”œâ”€â”€ train_vae.py           - EntraÃ®ne le VAE (exemple sur dataset MNIST)  
â”‚   â””â”€â”€ generate_image.py      - GÃ©nÃ¨re une image Ã  partir du VAE entraÃ®nÃ©  
â”œâ”€â”€ gpt2_lora_finetuned/       - **(ExpÃ©rimental)** ModÃ¨le GPT-2 fine-tunÃ© avec LoRA (poids adaptatifs)  
â”‚   â”œâ”€â”€ adapter_config.json    - Configuration LoRA du modÃ¨le  
â”‚   â”œâ”€â”€ adapter_model.bin      - Poids LoRA entraÃ®nÃ©s  
â”‚   â””â”€â”€ checkpoint-2/â€¦         - DonnÃ©es de checkpoint (issu de lâ€™entraÃ®nement LoRA)  
â”œâ”€â”€ new_test/                  - **Volet 2 :** pipeline de gÃ©nÃ©ration dâ€™articles de blog  
â”‚   â”œâ”€â”€ article_generator.py   - GÃ©nÃ©rateur dâ€™article de blog (classe *ArticleGenerator*, modÃ¨le LaMini-Flan-T5)  
â”‚   â”œâ”€â”€ summarization.py       - RÃ©sumeur de texte (classe *TextSummarizer*, rÃ©utilise DistilBART)  
â”‚   â”œâ”€â”€ similarity.py          - VÃ©rificateur de similaritÃ© (classe *SimilarityChecker*, MiniLM)  
â”‚   â”œâ”€â”€ ethical_filter_v2.py   - Filtrage Ã©thique v2 (fonction `ethical_filter` utilisant better-profanity)  
â”‚   â”œâ”€â”€ image_gen.py           - GÃ©nÃ©rateur dâ€™image (classe *ImageGenerator* utilisant Diffusers Stable Diffusion)  
â”‚   â”œâ”€â”€ pipeline.py            - Pipeline complet : enchaÃ®ne gÃ©nÃ©ration article, rÃ©sumÃ©, image, sauvegarde  
â”‚   â”œâ”€â”€ run_scheduler.py       - Ordonnancement planifiÃ© (gÃ©nÃ¨re des articles Ã  intervalles rÃ©guliers)  
â”‚   â”œâ”€â”€ blog_viewer.py         - Application Streamlit pour visualiser les articles gÃ©nÃ©rÃ©s (type blog)  
â”‚   â”œâ”€â”€ simple_app.py          - Application de dÃ©monstration simplifiÃ©e (optionnelle, ex. gÃ©nÃ©ration one-shot)  
â”‚   â”œâ”€â”€ requirements.txt       - Requirements spÃ©cifiques du volet 2 (versions de lib mises Ã  jour)  
â”‚   â””â”€â”€ outputs/               - Dossiers de sortie des articles de blog gÃ©nÃ©rÃ©s  
â”‚       â””â”€â”€ YYYYMMDD_HHMMSS/   - Un dossier par article gÃ©nÃ©rÃ© (horodatÃ©)  
â”‚           â”œâ”€â”€ article.md     - Article en Markdown (texte + rÃ©sumÃ© + stats + image intÃ©grÃ©e)  
â”‚           â””â”€â”€ meta.json      - MÃ©tadonnÃ©es JSON (titre, date, rÃ©sumÃ©, similaritÃ©, Ã©thique, imageâ€¦)  
â””â”€â”€ requirements.txt           - Requirements globaux du projet (volet 1 et dÃ©pendances communes)  

ğŸ‘‰ Remarque : Le dossier new_test/ contient la version aboutie du pipeline (volet 2). Les fichiers du niveau supÃ©rieur (hors new_test/) correspondent en grande partie au premier prototype (volet 1) et ne sont pas tous utilisÃ©s dans le volet 2. On retrouve par exemple deux versions de ethical_filter (simple et v2), de mÃªme que certaines fonctionnalitÃ©s expÃ©rimentales (vae_images, fine-tuning GPT-2) prÃ©sentes pour historique mais non actives dans la version finale du blog.
Installation et utilisation

    Prerequis : Assurez-vous dâ€™avoir Python 3.10+ installÃ©. Ces pipelines Ã©tant conÃ§us pour fonctionner sur CPU, aucune configuration GPU nâ€™est requise, mais cela implique des temps de calcul plus longs. 

1. RÃ©cupÃ©ration du projet â€“ Clonez le dÃ©pÃ´t GitHub ou tÃ©lÃ©chargez le dossier ai_generation/ et placez-vous dedans :

git clone https://github.com/Pistou27/hackathon2.git
cd hackathon2/ai_generation

2. Installation des dÃ©pendances â€“ Deux fichiers de requirements sont fournis :

    Pour le volet 1 (posts LinkedIn), vous pouvez installer les dÃ©pendances dâ€™origine :

pip install -r requirements.txt

Cela inclut Transformers 4.41, Torch 2.3, etc., suffisant pour exÃ©cuter le pipeline initial.

Pour le volet 2 (blog), des versions plus rÃ©centes de certaines librairies sont nÃ©cessaires (Transformers 4.54, Torch 2.7.1, Diffusers 0.28, etc.). Il est conseillÃ© dâ€™installer les requirements spÃ©cifiques :

    pip install -r new_test/requirements.txt

    (Selon votre environnement, ces installations peuvent Ãªtre faites dans un virtualenv distinct pour Ã©viter les conflits de versions. Sinon, installer directement le second requirements.txt couvrira la plupart des besoins du volet 1, car il contient des versions supÃ©rieures ou Ã©gales.)

3. Utilisation du volet 1 (pipeline posts LinkedIn) â€“ Ce prototype peut Ãªtre testÃ© de plusieurs faÃ§ons :

    Ligne de commande (pipeline complet) : exÃ©cutez python automate.py. Le script gÃ©nÃ©rera une sÃ©rie de posts de test (par exemple 5 prompts prÃ©dÃ©finis dans main.py ou automate.py) et affichera dans la console le texte gÃ©nÃ©rÃ©, Ã©ventuellement annotÃ© des scores/indicateurs (similaritÃ©, filtrage...).

    Interface Streamlit : lancez streamlit run app.py. Une interface web locale sâ€™ouvrira, permettant de saisir un sujet de post et dâ€™obtenir en direct le texte gÃ©nÃ©rÃ© filtrÃ©. (La page Streamlit configure une prÃ©sentation simple avec un thÃ¨me de couleur, et affiche le rÃ©sultat du pipeline Ã©tape par Ã©tape dans lâ€™application web).

    Planification automatique : le script scheduler.py (aussi rÃ©fÃ©rencÃ© comme automate_schedule dans la documentation) devait permettre dâ€™exÃ©cuter automate.py Ã  intervalle rÃ©gulier. Vous pouvez lâ€™adapter et lâ€™utiliser en faisant python scheduler.py (par dÃ©faut, il peut Ãªtre configurÃ© pour un certain timing â€“ veillez Ã  ajuster lâ€™intervalle voulu dans le code). Ce script dÃ©marrera un scheduler qui tourne en tÃ¢che de fond et gÃ©nÃ¨re pÃ©riodiquement de nouveaux contenus. Note : Ce volet Ã©tait un prototype, il se peut que la planification ou dâ€™autres aspects nÃ©cessitent des ajustements manuels dans le code pour fonctionner parfaitement.

4. Utilisation du volet 2 (pipeline blog) â€“ Câ€™est la partie recommandÃ©e pour une dÃ©monstration aboutie du projet.

    GÃ©nÃ©ration dâ€™un article : exÃ©cutez le script principal du pipeline avec un sujet en argument. Par exemple :

cd new_test
python pipeline.py "Les avancÃ©es de l'IA en 2025"

Ceci lancera la gÃ©nÃ©ration dâ€™un article de blog sur le thÃ¨me "Les avancÃ©es de l'IA en 2025". Par dÃ©faut, le pipeline crÃ©e aussi une image dâ€™illustration. Le rÃ©sultat complet sera sauvegardÃ© dans new_test/outputs/<timestamp>/ (le nom du dossier est la date/heure courante). Vous y trouverez le article.md (que vous pouvez ouvrir pour lire le contenu formatÃ© Markdown) et le illustration.png gÃ©nÃ©rÃ©, ainsi que meta.json. La console affichera le dÃ©roulement (Ã©tapes de gÃ©nÃ©ration, scores...) et le chemin du dossier rÃ©sultat.
Options: vous pouvez dÃ©sactiver la gÃ©nÃ©ration dâ€™image en ajoutant --no-image Ã  la commande. Vous pouvez aussi spÃ©cifier un rÃ©pertoire de sortie diffÃ©rent via --out_dir <path>. Si aucun sujet nâ€™est fourni en argument, le script utilisera un sujet par dÃ©faut (dÃ©fini dans le code, ex: "Les avancÃ©es rÃ©centes de l'IA").

Visualisation des articles : pour parcourir et lire aisÃ©ment les articles gÃ©nÃ©rÃ©s, lancez lâ€™interface Streamlit dÃ©diÃ©e :

    streamlit run new_test/blog_viewer.py

    Dans votre navigateur, vous verrez un tableau de bord listant les articles (dossiers dans outputs/) par ordre dÃ©croissant. Pour chaque article, le titre, la date de gÃ©nÃ©ration, le score de similaritÃ© et les labels du filtre Ã©thique sont affichÃ©s, suivis du contenu formatÃ© (titre, texte, rÃ©sumÃ©) et de lâ€™image. Cela simule un blog alimentÃ© automatiquement.

    GÃ©nÃ©ration planifiÃ©e automatique : utilisez le script new_test/run_scheduler.py pour lancer une gÃ©nÃ©ration pÃ©riodique. Par exemple, par dÃ©faut il peut Ãªtre codÃ© pour crÃ©er un article chaque heure pile. Vous pouvez lâ€™exÃ©cuter avec python new_test/run_scheduler.py. Le script utilise la bibliothÃ¨que schedule pour programmer la fonction de gÃ©nÃ©ration (job()) Ã  la frÃ©quence dÃ©sirÃ©e (ici toutes les heures, voir le code pour ajuster lâ€™intervalle ou le sujet). Laissez-le tourner en tÃ¢che de fond : il dÃ©clenchera pipeline.py Ã  chaque intervalle. (Par dÃ©faut dans le code fourni, le sujet est fixÃ© Ã  "Les avancÃ©es de l'IA en 2025" pour toutes les itÃ©rations â€“ vous pouvez modifier la variable topic dans job() pour varier les thÃ¨mes ou en sÃ©lectionner alÃ©atoirement).

5. ExtensibilitÃ© â€“ Vous pouvez adapter ces pipelines Ã  vos besoins. Par exemple, changer le modÃ¨le de gÃ©nÃ©ration (en choisissant un autre modÃ¨le Transformers plus grand pour de meilleurs rÃ©sultats â€“ en gardant Ã  lâ€™esprit les contraintes CPU), enrichir le filtre Ã©thique (intÃ©grer un classifieur de toxicitÃ© entraÃ®nÃ© en local, comme envisagÃ© en amÃ©lioration), ou modifier la frÃ©quence/les sujets de gÃ©nÃ©ration planifiÃ©e. Lâ€™architecture modulaire (classes sÃ©parÃ©es pour gÃ©nÃ©ration de texte, rÃ©sumÃ©, image, etc.) facilite les remplacements de composants. De mÃªme, lâ€™interface Streamlit peut Ãªtre customisÃ©e pour une meilleure prÃ©sentation ou pour permettre de dÃ©clencher manuellement la gÃ©nÃ©ration dâ€™un nouvel article Ã  la demande.
Limitations et performances (CPU)

    Tout le projet a Ã©tÃ© dÃ©veloppÃ© avec la contrainte CPU uniquement (pas de GPU ni cloud payant). Cela influence les temps de traitement : gÃ©nÃ©rer un article avec image peut prendre de 30 secondes Ã  quelques minutes selon votre machine. Il est recommandÃ© dâ€™utiliser un CPU puissant, et Ã©ventuellement de rÃ©duire certaines charges (par ex. dÃ©sactiver lâ€™image si non nÃ©cessaire, ou utiliser un modÃ¨le de diffusion plus lÃ©ger si disponible).

    Les modÃ¨les distillÃ©s (distilGPT2, DistilBART) ont Ã©tÃ© choisis pour leur lÃ©gÃ¨retÃ©, mais ils produisent un contenu moins riche/moins fiable que des modÃ¨les plus grands. Le compromis entre performance et qualitÃ© est notable. Dans le volet 2, le modÃ¨le Flan-T5 783M offre une meilleure qualitÃ© de texte que GPT-2 distillÃ©, au prix dâ€™un temps de calcul un peu supÃ©rieur.

    La gÃ©nÃ©ration dâ€™images via Stable Diffusion sur CPU est particuliÃ¨rement lourde. Le pipeline utilise 15 Ã©tapes de diffusion (au lieu de 50 ou 100 habituellement) et une rÃ©solution implicite limitÃ©e, ce qui rÃ©duit la qualitÃ©/dÃ©tail de lâ€™image pour gagner du temps. MalgrÃ© cela, produire une image reste lâ€™Ã©tape la plus lente. Si le temps ou les ressources sont un problÃ¨me, on peut envisager de dÃ©sactiver lâ€™image ou dâ€™utiliser une VAE prÃ©-entrainÃ© plus simple comme dans le volet 1 (mais les images seront alors trÃ¨s basiques).

    Ce projet Ã©tant un projet de hackathon, tout nâ€™est pas entiÃ¨rement abouti ou optimisÃ©. Des bugs mineurs peuvent subsister, et certaines parties expÃ©rimentales du code ne sâ€™intÃ¨grent pas dans le pipeline principal (par ex. le fine-tuning LoRA ou la lecture PDF ne sont pas exploitÃ©s dans le flux final). NÃ©anmoins, le second volet a Ã©tÃ© testÃ© de bout en bout et doit fournir un rÃ©sultat cohÃ©rent.

Auteurs et licence

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre dâ€™un hackathon par JÃ©rÃ©my Novico et Alexandre Perrault (GitHub : Jeynova et aperrault27), avec le support du profil GitHub Pistou27. Le dÃ©pÃ´t ne spÃ©cifie pas de licence open-source explicite. Par consÃ©quent, par dÃ©faut le code est non libre de droits (tous droits rÃ©servÃ©s aux auteurs). Si vous envisagez de rÃ©utiliser ou de diffuser ce code, il est conseillÃ© de contacter les auteurs pour accord.

Â© 2025 - Projet Hackathon2 AI Generation. Ce document README.md est une reconstitution dÃ©taillÃ©e du projet Ã  partir des sources disponibles, destinÃ©e Ã  expliquer le fonctionnement et la structure du systÃ¨me.